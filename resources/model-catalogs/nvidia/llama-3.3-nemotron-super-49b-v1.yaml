id: nvidia/llama-3.3-nemotron-super-49b-v1
canonical_slug: nvidia/llama-3.3-nemotron-super-49b-v1
hugging_face_id: nvidia/Llama-3_3-Nemotron-Super-49B-v1
name: 'NVIDIA: Llama 3.3 Nemotron Super 49B v1'
type: chat
created: 1744119494
description: |-
  Llama-3.3-Nemotron-Super-49B-v1 is a large language model (LLM) optimized for advanced reasoning, conversational interactions, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture Search (NAS) approach, significantly enhancing efficiency and reducing memory requirements. This allows the model to support a context length of up to 128K tokens and fit efficiently on single high-performance GPUs, such as NVIDIA H200.

  Note: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.
context_length: 131072
architecture:
  modality: text->text
  input_modalities:
    - text
  output_modalities:
    - text
  tokenizer: Other
  instruct_type: null
pricing:
  prompt: '0.00000013'
  completion: '0.0000004'
  input_cache_read: ''
  input_cache_write: ''
  request: '0'
  image: '0'
  web_search: '0'
  internal_reasoning: '0'
  unit: 1
  currency: USD
supported_parameters:
  - max_tokens
  - temperature
  - top_p
  - stop
  - frequency_penalty
  - presence_penalty
  - seed
  - top_k
  - logit_bias
  - logprobs
  - top_logprobs
model_provider: nvidia
