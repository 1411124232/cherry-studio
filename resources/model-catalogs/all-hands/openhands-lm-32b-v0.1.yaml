id: all-hands/openhands-lm-32b-v0.1
canonical_slug: all-hands/openhands-lm-32b-v0.1
hugging_face_id: all-hands/openhands-lm-32b-v0.1
name: OpenHands LM 32B V0.1
type: chat
created: 1743613013
description: |-
  OpenHands LM v0.1 is a 32B open-source coding model fine-tuned from Qwen2.5-Coder-32B-Instruct using reinforcement learning techniques outlined in SWE-Gym. It is optimized for autonomous software development agents and achieves strong performance on SWE-Bench Verified, with a 37.2% resolve rate. The model supports a 128K token context window, making it well-suited for long-horizon code reasoning and large codebase tasks.

  OpenHands LM is designed for local deployment and runs on consumer-grade GPUs such as a single 3090. It enables fully offline agent workflows without dependency on proprietary APIs. This release is intended as a research preview, and future updates aim to improve generalizability, reduce repetition, and offer smaller variants.
context_length: 16384
architecture:
  modality: text->text
  input_modalities:
    - text
  output_modalities:
    - text
  tokenizer: Other
  instruct_type: null
pricing:
  prompt: '0.0000026'
  completion: '0.0000034'
  input_cache_read: ''
  input_cache_write: ''
  request: '0'
  image: '0'
  web_search: '0'
  internal_reasoning: '0'
  unit: 1
  currency: USD
supported_parameters:
  - tools
  - tool_choice
  - max_tokens
  - temperature
  - top_p
  - stop
  - frequency_penalty
  - presence_penalty
  - repetition_penalty
  - top_k
  - min_p
  - seed
model_provider: all-hands
