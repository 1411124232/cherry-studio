id: qwen/qwen3-235b-a22b
canonical_slug: qwen/qwen3-235b-a22b-04-28
hugging_face_id: Qwen/Qwen3-235B-A22B
name: 'Qwen: Qwen3 235B A22B'
type: chat
created: 1745875757
description: Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a "thinking" mode for complex reasoning, math, and code tasks, and a "non-thinking" mode for general conversational efficiency. The model demonstrates strong reasoning ability, multilingual support (100+ languages and dialects), advanced instruction-following, and agent tool-calling capabilities. It natively handles a 32K token context window and extends up to 131K tokens using YaRN-based scaling.
context_length: 40960
architecture:
  modality: text->text
  input_modalities:
    - text
  output_modalities:
    - text
  tokenizer: Qwen3
  instruct_type: qwen3
pricing:
  prompt: '0.00000013'
  completion: '0.0000006'
  input_cache_read: ''
  input_cache_write: ''
  request: '0'
  image: '0'
  web_search: '0'
  internal_reasoning: '0'
  unit: 1
  currency: USD
supported_parameters:
  - max_tokens
  - temperature
  - top_p
  - reasoning
  - include_reasoning
  - seed
  - presence_penalty
  - frequency_penalty
  - repetition_penalty
  - top_k
  - tools
  - tool_choice
  - stop
  - response_format
  - structured_outputs
  - logit_bias
  - logprobs
  - top_logprobs
  - min_p
model_provider: qwen
