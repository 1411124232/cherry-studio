id: thudm/glm-z1-32b
canonical_slug: thudm/glm-z1-32b-0414
hugging_face_id: THUDM/GLM-Z1-32B-0414
name: 'THUDM: GLM Z1 32B'
type: chat
created: 1744924148
description: |-
  GLM-Z1-32B-0414 is an enhanced reasoning variant of GLM-4-32B, built for deep mathematical, logical, and code-oriented problem solving. It applies extended reinforcement learning—both task-specific and general pairwise preference-based—to improve performance on complex multi-step tasks. Compared to the base GLM-4-32B model, Z1 significantly boosts capabilities in structured reasoning and formal domains.

  The model supports enforced “thinking” steps via prompt engineering and offers improved coherence for long-form outputs. It’s optimized for use in agentic workflows, and includes support for long context (via YaRN), JSON tool calling, and fine-grained sampling configuration for stable inference. Ideal for use cases requiring deliberate, multi-step reasoning or formal derivations.
context_length: 32000
architecture:
  modality: text->text
  input_modalities:
    - text
  output_modalities:
    - text
  tokenizer: Other
  instruct_type: deepseek-r1
pricing:
  prompt: '0.00000024'
  completion: '0.00000024'
  input_cache_read: ''
  input_cache_write: ''
  request: '0'
  image: '0'
  web_search: '0'
  internal_reasoning: '0'
  unit: 1
  currency: USD
supported_parameters:
  - max_tokens
  - temperature
  - top_p
  - reasoning
  - include_reasoning
  - stop
  - frequency_penalty
  - presence_penalty
  - seed
  - top_k
  - min_p
  - repetition_penalty
  - logit_bias
model_provider: thudm
